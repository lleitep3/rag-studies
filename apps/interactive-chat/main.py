#!/usr/bin/env python3
"""
ü§ñ Interactive RAG Chat - Main Application
==========================================

Aplicativo principal do chat interativo com o Code Assistant RAG.
Coordena todos os m√≥dulos e fornece uma experi√™ncia completa de chat.
"""

import sys
import os
from pathlib import Path
import argparse

# Adiciona m√≥dulos locais ao path
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from colored_output import ColoredOutput
from code_assistant import CodeAssistant
from chat_interface import ChatInterface


def parse_arguments():
    """Processa argumentos de linha de comando"""
    parser = argparse.ArgumentParser(
        description="RAG Code Assistant - Chat Interativo",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python main.py                          # Configura√ß√£o padr√£o
  python main.py --llm ollama             # For√ßa uso do Ollama
  python main.py --model llama3.2:3b      # Usa modelo espec√≠fico
  python main.py --path ../other-project  # Carrega c√≥digo de outro projeto
  python main.py --pattern "**/*.py"      # Padr√£o personalizado de arquivos

Modelos dispon√≠veis (Ollama):
  - llama3.2:1b (r√°pido, menor qualidade)
  - llama3.2:3b (balanceado)
  - gemma2:2b (alternativa Google)
        """,
    )

    parser.add_argument(
        "--path",
        "-p",
        default="../../src",
        help="Caminho para o c√≥digo fonte (default: ../../src)",
    )

    parser.add_argument(
        "--pattern",
        "-f",
        default="**/*.py",
        help="Padr√£o de arquivos a carregar (default: **/*.py)",
    )

    parser.add_argument(
        "--llm",
        "-l",
        choices=["ollama", "gemini"],
        default="ollama",
        help="Tipo de LLM a usar (default: ollama)",
    )

    parser.add_argument(
        "--model",
        "-m",
        default="llama3.2:1b",
        help="Nome do modelo LLM (default: llama3.2:1b)",
    )

    parser.add_argument(
        "--temperature",
        "-t",
        type=float,
        default=0.1,
        help="Temperatura para gera√ß√£o de texto (default: 0.1)",
    )

    parser.add_argument(
        "--max-docs",
        "-d",
        type=int,
        default=3,
        help="M√°ximo de documentos para contexto (default: 3)",
    )

    parser.add_argument(
        "--quiet", "-q", action="store_true", help="Modo silencioso (menos output)"
    )

    return parser.parse_args()


def check_requirements(args):
    """Verifica se os pr√©-requisitos est√£o atendidos"""
    issues = []

    # Verifica se o caminho do c√≥digo existe
    code_path = Path(args.path)
    if not code_path.exists():
        issues.append(f"Caminho do c√≥digo n√£o existe: {code_path}")
    elif not code_path.is_dir():
        issues.append(f"Caminho n√£o √© um diret√≥rio: {code_path}")

    # Verifica se Ollama est√° dispon√≠vel (se necess√°rio)
    if args.llm == "ollama":
        try:
            import requests

            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code != 200:
                issues.append("Ollama n√£o est√° rodando ou n√£o est√° acess√≠vel")
        except Exception:
            issues.append("N√£o foi poss√≠vel verificar o status do Ollama")

    # Verifica se modelo Gemini est√° configurado (se necess√°rio)
    if args.llm == "gemini":
        if not os.getenv("GOOGLE_API_KEY"):
            issues.append("GOOGLE_API_KEY n√£o est√° configurada para usar Gemini")

    return issues


def show_welcome_message(args):
    """Mostra mensagem de boas-vindas"""
    print("\n" + "ü§ñ" + "=" * 60 + "ü§ñ")
    ColoredOutput.print_colored(
        "   RAG CODE ASSISTANT - Chat Interativo", ColoredOutput.CYAN, bold=True
    )
    print("ü§ñ" + "=" * 60 + "ü§ñ")

    if not args.quiet:
        ColoredOutput.info("‚öôÔ∏è Configura√ß√µes:")
        print(f"   ‚Ä¢ C√≥digo fonte: {args.path}")
        print(f"   ‚Ä¢ Padr√£o de arquivos: {args.pattern}")
        print(f"   ‚Ä¢ LLM: {args.llm}")
        print(f"   ‚Ä¢ Modelo: {args.model}")
        print(f"   ‚Ä¢ Temperatura: {args.temperature}")
        print(f"   ‚Ä¢ Max documentos por consulta: {args.max_docs}")


def main():
    """Fun√ß√£o principal"""
    try:
        # Parse argumentos
        args = parse_arguments()

        # Mostra mensagem de boas-vindas
        show_welcome_message(args)

        # Verifica pr√©-requisitos
        if not args.quiet:
            ColoredOutput.info("üîç Verificando pr√©-requisitos...")

        issues = check_requirements(args)
        if issues:
            ColoredOutput.error("‚ùå Problemas encontrados:")
            for issue in issues:
                print(f"   ‚Ä¢ {issue}")

            ColoredOutput.info("\nüí° Poss√≠veis solu√ß√µes:")
            if any("Ollama" in issue for issue in issues):
                print("   ‚Ä¢ Inicie o Ollama: ollama serve")
                print("   ‚Ä¢ Verifique se o modelo est√° instalado: ollama list")
            if any("GOOGLE_API_KEY" in issue for issue in issues):
                print("   ‚Ä¢ Configure sua chave: export GOOGLE_API_KEY=sua_chave")
                print("   ‚Ä¢ Ou use arquivo .env com GOOGLE_API_KEY=sua_chave")
            if any("Caminho" in issue for issue in issues):
                print(f"   ‚Ä¢ Verifique se {args.path} existe e cont√©m arquivos Python")
                print("   ‚Ä¢ Ou especifique outro caminho com --path")

            return 1

        # Cria e configura assistente
        assistant = CodeAssistant(
            loader_type="python",
            llm_type=args.llm,
            llm_model=args.model,
            llm_temperature=args.temperature,
        )

        # Configura sistema
        if not assistant.setup(args.path, args.pattern):
            ColoredOutput.error("‚ùå Falha na configura√ß√£o do sistema")
            return 1

        # Cria e inicia interface de chat
        interface = ChatInterface(assistant)
        interface.start_chat()

        return 0

    except KeyboardInterrupt:
        print("\n")
        ColoredOutput.warning("Aplicativo interrompido pelo usu√°rio")
        return 0
    except Exception as e:
        ColoredOutput.error(f"Erro fatal: {str(e)}")
        if not args.quiet if "args" in locals() else True:
            import traceback

            traceback.print_exc()
        return 1


def quick_start():
    """Fun√ß√£o para in√≠cio r√°pido com configura√ß√£o padr√£o"""
    print("\nüöÄ RAG Code Assistant - In√≠cio R√°pido")
    print("=" * 40)

    # Configura√ß√£o padr√£o
    assistant = CodeAssistant()

    if assistant.setup():
        ColoredOutput.success("‚úÖ Sistema configurado com sucesso!")
        ColoredOutput.info("üí° Inicie o chat interativo com: python main.py")
    else:
        ColoredOutput.error("‚ùå Falha na configura√ß√£o")


if __name__ == "__main__":
    sys.exit(main())
